<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Driven by Reinforcement Learning &#8211; Marc Nevin</title>
    <link rel="dns-prefetch" href="//fonts.googleapis.com">
    <link rel="dns-prefetch" href="//fonts.gstatic.com">
    <link rel="dns-prefetch" href="//maxcdn.bootstrapcdn.com">
    <link rel="dns-prefetch" href="//cdnjs.cloudflare.com">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="AI Camp takes on the DeepRacer">
    <meta name="robots" content="all">
    <meta name="author" content="Marc Nevin">
    <meta name="keywords" content="aws, machine-learning, deepracer, deep-learning">
    <link rel="canonical" href="http://localhost:4000/driven-by-reinforcement-learning">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for Marc Nevin" href="/feed.xml" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/style.css?202002091735" type="text/css">

    <!-- Fonts -->
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
      <link href="//maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" rel="stylesheet">
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_GB">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Driven by Reinforcement Learning">
    <meta property="og:description" content="Marc's musings, blogs and technology rambling captured in one neat place.">
    <meta property="og:url" content="http://localhost:4000/driven-by-reinforcement-learning">
    <meta property="og:site_name" content="Marc Nevin">
    

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
        <meta name="twitter:site" content="@M_Nevin" />
        <meta name="twitter:creator" content="@M_Nevin" />
    
    <meta name="twitter:title" content="Driven by Reinforcement Learning" />
    <meta name="twitter:description" content="AI Camp takes on the DeepRacer" />
    <meta name="twitter:url" content="http://localhost:4000/driven-by-reinforcement-learning" />
    

    <!-- Icons -->
    <link rel="shortcut icon" href="/favicon.ico">

    
    <script type="text/javascript">
       (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
       (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
       m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
       })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
       ga('create', 'UA-157875972-1', 'auto');
       ga('send', 'pageview');
    </script>
    
</head>

<body class="site animated fade-in-down">

  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="/" class="site-title">Marc Nevin</a>
      <nav class="site-nav">
        



    
    
    
    
        <a class="nav-link" href="/about/">About</a>
    

    


      </nav>
      <div class="clearfix"></div>
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        


<div class="post-header mb2">
  <h1>Driven by Reinforcement Learning</h1>
  <span class="post-meta">Oct 17, 2019 |</span>
  
  <span class="post-meta small">
  
    10 minute read
  
  </span>
</div>

<article class="post-content">
  <p>This blog was originally posted <a href="https://medium.com/kainos-applied-innovation/driven-by-reinforcement-learning-64dbd41ae12f">here</a> on medium!</p>

<p>At this year’s Kainos AI Camp in Belfast and Birmingham, the Applied Innovation team worked with some staff from AWS to deliver two DeepRacer Day Workshops at the camps!</p>

<hr />

<p>AI Camp is a 2-week long camp full of theory, workshops and practical sessions to give students a strong introduction to the field of artificial intelligence and machine learning, and how it is being used to benefit our everyday lives.</p>

<p>This year, two days of each camp were dedicated to AWS; the first covering AWS SageMaker and deploying machine learning models. The second day was a workshop and racing day for the AWS DeepRacer — teaching students about applications of AI models, reinforcement learning and getting some competitive spirit going before the hackathon that’s at the end of AI Camp.</p>

<h1 id="what-is-the-aws-deepracer">What is the AWS DeepRacer?</h1>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/qkgr64xjrzjay9sd2qax.png" alt="A DeepRacer forward-facing" /></p>

<p>A fully autonomous 1/18th scale race car driven by reinforcement learning, 3D racing simulator, and global racing league. Featuring a Linux distribution with enough computing power and storage to run a fairly intense reinforcement learning model at some consistent speeds, the car is built on top of a popular model RC racing car chassis.</p>

<p>After developing and training, the model is then downloaded to a physical car to be raced around a massive 8m x 4m track. We followed the AWS competition rules used for their racing events;</p>
<ul>
  <li>You have 4 minutes on the track to complete as many laps as you can.</li>
  <li>The fastest lap is your submitted time.</li>
  <li>Come off the track and your racer is placed where it came off.</li>
  <li>Come off the track 3 times and your lap is marked as ‘Did Not Finish’.</li>
</ul>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/0tz8l44amev36ydjim9g.jpeg" alt="Person walking around a large RC car track" /></p>

<p>Using the <a href="https://aws.amazon.com">AWS Console</a> you can develop reinforcement learning models for the car and train them by setting the model to race around a simulated track for a few hours. The racers are aimed not only at just their racing competition, but they’re also for education, mostly on how reinforcement learning works and its applications. For both of our events, we started with some refreshers on different aspects of machine learning before covering what exactly reinforcement learning is, with the model building acting as the exercise to reinforce what they’ve learnt.</p>

<p>If you want to build some models or are interested in how it works, here are the basics of Reinforcement Learning that we covered with the students;</p>

<h1 id="reinforcement-learning">Reinforcement Learning</h1>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/p3m2l4is1jrox2aul2bl.png" alt="A graph for explaining were Reinforcement learning sits compared to AI" /></p>

<p>If we look at Artificial Intelligence as an umbrella term, one of the biggest aspects under it is Machine Learning, which is often divided down into Supervised and Unsupervised Learning. Reinforcement learning is often forgotten in place of its more popular siblings, but still merits itself a category of its own for being somewhere between Supervised and Unsupervised.</p>

<p>The quote AWS gives us is;</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Reinforcement learning, in the context of artificial intelligence, 
is a type of dynamic programming that trains algorithms using 
a system of reward and punishment

— AWS DeepRacer Training
</code></pre></div></div>

<p>To break that down; a reinforcement learning algorithm, or agent, learns by interacting with its environment. The agent receives rewards by performing correctly and penalties for performing incorrectly.</p>

<p>The agent <strong>learns</strong> without intervention from a human by maximizing its reward and minimizing its penalty.</p>

<hr />

<p>To explain that further, let’s take the example of a robot jumping over some obstacles; first, you could give the robot the ability to jump at various distances while approaching an obstacle.</p>

<p>For the first test, let it jump either 2 metres away, 1 metre away, half a metre away, or even 0 metres away which causes it to crash into the obstacle before actually launching upwards.</p>

<p>After a lot of trial and error with when to jump, the robot will eventually learn that it will receive a point by jumping just before hitting an obstacle (say 0.5 metres) — because jumping then leads to a successful clearing of the obstacle.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/iyqyvx6prnyfqzki3fna.gif" alt="Gif of Robot clearing obstacles" />
<em>From the AWS DeepRacer Training Course</em></p>

<p>Your robot will also learn that it will quickly lose points by jumping too early or too late — as jumping when too far from or too close to an obstacle will lead to a crash.</p>

<p>The reward and punishment, in the form of points, positively reinforces the action of jumping at that ideal point, eventually making your robot really good at clearing the obstacles.</p>

<p>This game can get more complicated if the goal becomes how quickly the robot can clear 10 obstacles in a row, or how well it can clear obstacles that require changing its direction. In a more complicated game, the robot could gain control over its speed and its ability to move in different directions.</p>

<p>By using reinforcement learning to help the robot succeed at this new game the robot is now not only experimenting with different timings of its jumps but the speed at which it runs and the specific direction of its jumps. Like the timing of jumps, the robot will receive rewards and punishments for the speeds and directions that result in more points or fewer points.</p>

<p>Again, through a lot of trial and error, your robot will eventually learn the right mix of jumping time, speed, and direction to successfully clear a whole series of obstacles.</p>

<p>Applying this concept to the DeepRacer we can reward our Racer for staying on the track, speeding up etc, until the car can begin to complete the entire circuit. This GIF ties in the different elements of the DeepRacer and their relation to Reinforcement learning:</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/55ldi2g9mm66yrpvslx7.gif" alt="Gif of deepracer terms" />
<em>From AWS: GIF of the reinforcement terms on the DeepRacer</em></p>

<p>Back to the camp — after taking the students through this theory it was time to get them started on building their models.</p>

<p>#The DeepRacer Console</p>

<p>To autonomously race the car you have to develop and train your own machine learning model, to do this you have to use the AWS DeepRacer console. There we are given a model that we can shape various aspects of, mainly the reward algorithm, hyperparameter tuning and the action space. The amount of options for this leads to an impossibly large number of possibilities of configurations for the model.</p>

<p>The reward algorithm lets you punish or reward the car encouraging it to complete the track in faster times, the variables you can control for this are the parameters that the car can measure. There’s a load of these parameters, most are self-explanatory aspects of the car and this diagram helps capture exactly how all of them relate to the car:</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/0fkmlijdt6gfg6v4r1r0.png" alt="Diagram of the DeepRacer with measurements it can take noted" />
<em>From AWS: DeepRacer Parameters and how they relate to the car</em></p>

<p>We took the students through each parameter at the time but a handy online resource, that the AWS team pointed us to, explained all the parameters that the DeepRacer has and how reinforcement learning applies to it. Find it <a href="https://d2k9g1efyej86q.cloudfront.net/">here</a>!</p>

<p>The hyperparameters offer a range of different options for tuning the model for the DeepRacers. We covered what each of them meant with the students but the important thing for them to know is how they can change your reward algorithm. Most people find that through trial and error, cloning, and retraining models — they can discover what seems to work best for a given model.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/n7ewy9g1h4eunz42mlha.png" alt="Hyperparameters of the deepracer" />
<em>The different hyperparameters of the DeepRacer</em></p>

<p>After developing their reward algorithms and setting their hyperparameters, we can begin to train our models. Training is done in a fully <a href="https://aws.amazon.com/robomaker/">simulated environment</a> of the track with a physics engine acting of every aspect of the car and track to try and best represent the real track. The model is set up to run in this environment for hours on the track and learn over a time that we have specified up to 8 hours.</p>

<p>Once a model is trained, we can evaluate its performance by racing it on a simulated track, giving us some rough times for its performance and how much of the track it was able to complete. If the digital car completed at least one lap of the track then we downloaded the models and got ready to race them on the non-digital cars!</p>

<h1 id="racing-in-belfast">Racing In Belfast</h1>
<p>After uploading the models to the cars we were able to set them off on the track and get them racing, below are some shots of the students, the cars racing, and their reactions:</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/4ojsfdlx2awt9whs60lm.png" alt="A person following the car across the track" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/2pr0f9iqaa0if7yi79ao.jpeg" alt="view of the entire track" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/wbnscjydp3bqjgfsgtec.jpeg" alt="Deepracer cornering" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/b46ueun1o8h5co4bcm5i.png" alt="Author following the car around the track" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/y5nkc8951gy9njs8jbox.png" alt="Rearview of the car" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/ztza1he2q860r622inlk.jpeg" alt="AI camp mentors watching the race" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/d2pt0ssdv9xsbivgiz6b.jpeg" alt="Action shot of the car" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/bzh7nx9heylh4e56lk0n.jpeg" alt="Person giving a presentation on deepracer" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/tlke4gwel538rhs49v2c.png" alt="Team of students celebrating" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/pszdfungcozh6zvzo3sr.jpeg" alt="A team of students working on their ML models" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/yc4ifzvtd5by46cj1x2i.png" alt="A team reviewing their models before a lap" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/s35lz023pc54662ha0d1.png" alt="A team watching with anticipation" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/6fyawrm88ddnw50dhvcc.png" alt="Group of three students watching the race" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/m9lbxgzcd6w4i36opqxo.jpeg" alt="Mentor helping the students build their models" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/opol1rvez8t0h5amkdw9.jpeg" alt="Students watching the race" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/ltyqf639ppfu8sa9shgd.jpeg" alt="Scoreboard of the top times" />
<em>Some of the pictures captured at AI Camp Belfast</em></p>

<p>We got some great times with the winner hitting a time the AWS staff said would’ve placed at the AWS London Summit a few months before!</p>

<h1 id="racing-in-birmingham">Racing In Birmingham</h1>
<p>After a short break, we were back racing, this time in Birmingham! Again we took the students through all the theory, building models and then getting ready to race!</p>

<p>Below we’ve got some photos and videos of the cars racing at the Birmingham AI Camp:</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/5ekf4uq9a3wxngkdi02i.png" alt="Students watching their first model race" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/u9hqrvzss4ksqqezp0kw.png" alt="Author following the car around the track" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/g2mmyu7kwab6i1ydiwg2.png" alt="Attendees watching their model" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/qjg55dzijdp0f0pb7wjo.png" alt="Students using ipad to control their model" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/yxuyq6bzfw9nmvwnlcuh.png" alt="Laptop showing the training running for a new model" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/pxodtxfbay3ahv3uqmv2.png" alt="Large group of students watching the race" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/wxposo4krcoviawx2gh5.png" alt="Kainos and AWS staff rotating the cars on the track" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/76ly9e0klgvimkq8rip7.png" alt="A man following the car around the track" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/d1nq0gd4lcjscf6qsrft.png" alt="Group of mentors watching the race" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/9e7z1561qg8icvuvqamf.png" alt="Group of students looking at their car with AWS staff" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/qi3la9grgkepom8p5lw5.png" alt="AWS staff resetting an off the track car" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/irr8zy771sd4mfm0b79e.png" alt="Groups of students checking their model progress" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/vs7ywah63q21nmasosed.png" alt="Some students working on their models" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/dzuw4qc1sd01zpttmtdl.png" alt="All the campers reviewing their models" />
<img src="https://dev-to-uploads.s3.amazonaws.com/i/mo12jgnqgfubi2us43kd.jpeg" alt="Leaderboard for the day's racing" />
<em>Some Pictures of AI Camp Birmingham</em></p>

<p>After challenging the students to try to beat the great times in Belfast, they didn’t let us down, we got a blazingly fast time of 8.72 seconds. It was the fastest the AWS staff had seen in person, never mind placing in London as the Belfast model would’ve, they said that time would’ve won.</p>

<hr />

<p>Both sets of campers really enjoyed the events and got super competitive with it all, they all went to complete the rest of AI Camp and its hackathon. But after running both sessions we learnt some lessons for competing with our own models in future!</p>

<h1 id="tips--tricks">Tips &amp; Tricks</h1>

<p>So from running both camps and speaking to the team we definitely got some tips we want to pass on to you;
This first once might seem obvious for someone who’s used to machine learning concepts, but you need to build your models to generalise — be wary of convergence;</p>
<iframe width="560" height="420" src="http://www.youtube.com/embed/Mbm-Lv5Un3Q?color=white&amp;theme=light"></iframe>

<p>Training time is an important thing to keep in mind with convergence, training for a maximum of 8 hours, cloning it, and running it again doesn’t normally lead to an effective model. Typically you see much more success with smaller training increments of 1–2 hours before cloning and tweaking the hyperparameters.</p>

<p>Next up is analysis; the DeepRacer console is useful but digging deeper into the training and evaluation logs is where you can start to see exact points causing you problems and start shaving vital seconds off your lap times. These two GitHub repos, <a href="https://github.com/awslabs/amazon-sagemaker-examples/tree/master/reinforcement_learning/rl_deepracer_robomaker_coach_gazebo">here</a> and <a href="https://github.com/aws-samples/aws-deepracer-workshops/tree/master/log-analysis">here</a>, proved to be extremely useful in building our own models and allowed us really to get ‘under the hood’ of the DeepRacer.</p>

<p>And finally, keep in mind the actual real-world limitations of the car when building your models — these cars have computational limits that the simulator doesn’t. The training simulator can pass far more complex reward functions than the DeepRacer itself can. It’s also worth saying some aspects of the model, i.e. waypoints, just don’t exist in the real world and accuracy in the model evaluation won’t reflect when you try it on the track.</p>

<p>An indispensable resource for taking your models further is the <a href="https://deepracing.io/#about">Deep Racer Community</a>, this website and associated Slack group is a gold mine of tips and tricks. It includes topics for everything, including how to train models offline and avoid those large training bills!</p>

<h1 id="thats-all">That’s all!</h1>

<p>We’re going to take everything we learnt to start building our own models before we head back out to the track but for all of you its time to get started.</p>

<p>Here’s the landing page for the <a href="https://signin.aws.amazon.com/deepracer/home?region=us-east-1">AWS DeepRacer Console</a>, there are prizes for the virtual leagues and the community leagues if you can’t make it to an AWS Summit — happy racing!</p>

<hr />

<p>If you want to read more about some of the work the Applied Innovation team does, check out our <a href="https://medium.com/kainos-applied-innovation">Medium publication</a>.</p>

<p>Interested in AI Camp? Find out more and sign up for updates <a href="https://www.kainos.com/careers/students/aicamp">here</a>!</p>

</article>


  <div class="share-page">
  <div class="share-links">
    Share:

    

    
      <a class="fa fa-twitter" href="https://twitter.com/intent/tweet?text=Driven+by+Reinforcement+Learning&amp;url=http%3A%2F%2Flocalhost%3A4000%2Fdriven-by-reinforcement-learning" rel="nofollow" target="_blank" title="Share on Twitter"></a>
    

    

    
      <a class="fa fa-linkedin" href="http://www.linkedin.com/shareArticle?url=http%3A%2F%2Flocalhost%3A4000%2Fdriven-by-reinforcement-learning&amp;title=Driven+by+Reinforcement+Learning" rel="nofollow" target="_blank" title="Share on LinkedIn"></a>
    

    

    

    
      <a class="fa fa-reddit" href="http://reddit.com/submit?url=http%3A%2F%2Flocalhost%3A4000%2Fdriven-by-reinforcement-learning&amp;title=Driven+by+Reinforcement+Learning" rel="nofollow" target="_blank" title="Share on Reddit"></a>
    

    

    
      <a class="fa fa-hacker-news" onclick="parent.postMessage('submit','*')" href="https://news.ycombinator.com/submitlink?u=http%3A%2F%2Flocalhost%3A4000%2Fdriven-by-reinforcement-learning&amp;t=Driven+by+Reinforcement+Learning" rel="nofollow" target="_blank" title="Share on Hacker News"></a>
    
  </div>
</div>








  <h3 class="related-post-title">Related Posts</h3>
  <ul class="related-posts">
    
    <li>
      <a href="/a-beginners-guide-to-cron" class="post-link">
          A beginners guide to Cron
      </a>
    </li>
    
  </ul>


      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
    <div class="left">
      <small>
        &copy; 2020 Marc Nevin
      </small>
    </div>
    
      <div class="social-icons right">
  
    <a class="fa fa-linkedin" href="https://www.linkedin.com/in/marcnevin" target="_blank"></a>
    
  
    <a class="fa fa-github" href="https://github.com/Nevin243" target="_blank"></a>
  
  
    <a class="fa fa-twitter" href="https://twitter.com/M_Nevin" target="_blank"></a>
  
  <!---->
  <a href="https://dev.to/m_nevin" target="_blank">
      <i class="fab fa-dev"></i>
  </a>
  <!---->
  
  <a class="fa fa-rss" href="/feed.xml" target="_blank"></a>
</div>
<div class="clearfix"></div>

    
  </div>
</footer>
<script type="text/javascript">
    if ("serviceWorker" in navigator) {
      navigator.serviceWorker.register("/sw.js")
    }
</script>

</body>
</html>
